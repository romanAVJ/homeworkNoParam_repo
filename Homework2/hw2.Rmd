---
title: "Tarea 2"
author: "Santiago, Sofía, Román, Individuo4"
date: "8/2/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(knitr)
library(tidyverse)
```


```{r}
set.seed(20200208) #created at date

# assigning number of excercises 
(people_3quest <- sample(x = c("Luis","Roman","Sant","Sof"),replace = F, size = 2)) #people with 3 questions, by alphabetic order


# assinging excersises
number_ex <- 1:10 #excercises
cat("\nEjercicios Luis: ")
(ex_luis <- sample(x = number_ex, replace = F, size = 3))
number_ex <- number_ex[! number_ex %in% ex_luis] #removing questions 

cat("\nEjercicios Roman: ")
(ex_roman <- sample(x = number_ex, replace = F, size = 2))
number_ex <- number_ex[! number_ex %in% ex_roman] #removing questions 

cat("\nEjercicios Sant: ")
(ex_sant <- sample(x = number_ex, replace = F, size = 3))
number_ex <- number_ex[! number_ex %in% ex_sant] #removing questions 

cat("\nEjercicios Sof: ")
(ex_sof <- number_ex)
```


##Ejercicio 6
A una muestra de tres niñas y cinco niños se les dan instrucciones sobre cómo armar un
lego. Luego se les pide armar el lego una y otra vez hasta que lo hagan correctamente.
El número de repeticiones necesarias para una terminación correcta son 1,2, y 5 para
las niñas, y 4,8,9,10 y 12 para los niños. Encontrar el p−valor de la alternativa que en
promedio las niñas aprenden la actividad más rápido que los niños, y encontrar el intervalo
de confianza estimado de la diferencia $\theta = M_Y − M_X$ con un coeficiente de confianza al
menos igual a 0.85, usando la prueba de la mediana.

```{r}
na<-c(1,2,5)
no<-c(4,8,9,10,12)
n<-length(nar)
m<-length(nor)
N<-n+m
names(na) <- rep("x",n)
names(no) <- rep("Y",m)
```
 Primero encontremos el p-value de $H_0:M_Y = M_X$ $H_0:M_Y < M_X$en promedio las niñas aprenden más rápido que los niños.

Tenemos dos muestras aleatorias independientes, entonces podemos usar el Mann-whitney test.

Sacamos los rangos para ambos grupos
```{r}
(w <- sort(c(na,no)))
(Rw <- rank(w,ties.method = "average"))
```

Ahora obtenemos la suma de los rangos de cada grupo

```{r}
Rw[names(Rw) == "x"]
(Tx <- sum(Rw[names(Rw) == "x"]))
```

```{r}
(T1<-Tx-n*(N+1)/2)/sqrt(n*m/(N*(N-1))*sum(Rw^2) - n*m*(N+1)^2/(4*(N-1)))
(pval <- 1-pnorm(T1))
```

No rechazamos con un p-value de 1 y un nivel de confianza de 0.05

Ahora agámoslo con funciones

```{r}
wilcox.test(x=na,y=no,alternative = "greater",
            paired = FALSE, exact = TRUE, correct = FALSE,
            conf.int = TRUE, conf.level = 0.85,
             digits.rank = Inf)
```

Notemos que el p-value es grande, entonces no rechazamos la hipótesis nula, es decir, la mediana de las niñas es mayor que la de los niños.

El intervalo de confianza para $\theta = M_Y − M_X$ es

```{r}
wilcox.test(x=na,y=no,alternative = "greater",
            paired = FALSE, exact = TRUE, correct = FALSE,
            conf.int = TRUE, conf.level = 0.85,
             digits.rank = Inf)$conf.int
```

## Ejercicio 9

Ocho voluntarios fueron reclutados para probar la eficacia de usar un telescopio en un
rifle. Se cree que el uso del telescopio aumentará los puntajes en un rango de tiro. Para
probar esto, los ocho voluntarios se les pidió usar un rifle en un rango de tiro, tanto con
un telescopio en la mira como sin telescopio en la mira de los rifles, usando un patrón
alternado aleatorio entre ambos. Los resultado fueron:

¿Las miras telescópicas resultan en puntajes más altos?

a) Usar una prueba basada sólo en rangos. Encontrar el p-valor en tres formas diferentes:
(1) encontrar el p-valor exacto, (2) Usar la aproximación normal sin corrección por
continuidad y (3) Usar la aproximación normal con la corrección de continuidad.


```{r}
w<-c(96, 93, 89, 88, 85, 83, 80, 77)
z<-c(92, 92, 89, 96, 82, 79, 80, 78)
dif<-w-z
```

(1) p-value exacto
```{r}
wilcox.test(w,z,alternative = "two.sided",
            paired = FALSE, exact = TRUE, correct = FALSE,
            conf.int = TRUE, conf.level = 0.85,
             digits.rank = Inf)
```

(2)Usar la aproximación normal sin corrección por continuidad ¿cómo se le deja la normal sin que se corrija? Me sale igual que con p-value exacto

```{r}
wilcox.test(w,z,alternative = "two.sided",
            paired = FALSE, exact = FALSE, correct = FALSE,
            conf.int = TRUE, conf.level = 0.85,
             digits.rank = Inf)
```

(3)Usar la aproximación normal con la corrección de continuidad
```{r}
wilcox.test(w,z,alternative = "two.sided",
            paired = FALSE, exact = FALSE, correct = TRUE,
            conf.int = TRUE, conf.level = 0.85,
             digits.rank = Inf)
```

b)Usar una prueba basada en normalidad. FALTA ESTA

```{r}
shapiro.test(dif)
```
Tiene un p-value mayor a 0.05, entonces no rechazamos $H_0$.

c)Usar una prueba de aleatorización tipo Fisher

```{r}
#fisher.test(w, z, alternative = "two.sided") la veremos en clase
```


d)Encontrar un intervalo de confianza para la mejora en el puntaje obtenida usando una
mira telescópica
```{r}
library(gmodels)
mejora<-dif
ci(mejora, confidence=0.95)
```
Tenemos que el intervalo es [-2.876358, 3.626358]






# Ejercicio 5

- Cantidad __mediana__ de sueño es de 7,5 hrs, con d.est de 1.5 hrs.

- El 5% de la población duerme 6 o menos.

- El otro 5% duerme  9 o más hrs.

- n = 8. 

```{r,'ej5 data'}
# data
X <- c(7.2,8.3,5.6,7.4,7.8,5.2,9.1,5.8)
n <- length(data)
# kable(as.array(data),col.names = c("Horas de sueno"))
# quantiles
q_vec <- c(0.05,0.5,0.95)

# empirical quantiles
empq_vec <- c(6,7.5,9)

#alpha
alpha <- 0.05

```


Determinar si los mexicanos duermen menos hoy que lo que hicieron en el pasado. Probarse las hipótesis para los cuantiles 0.05, 0.5 y 0.95.

### Solución:

Como se quiere determinar si los mexicanos duermen __menos__ que hoy, se hará una prueba de hipótesis para los cuantíles concernientes con la prueba de hipótesis 
$$\mathcal{H}_{0}: \kappa_{p} \le k_{p}^{0}. $$

#### Forma con el valor de K

```{r,'ej5 testHip K'}

cat("Pruebas de hipótesis para Kp")
for(i in 1:3)
{
  cat(paste("\n\n Para p = ",toString(i), sep = " "))
  # find k
  K <- sum(ifelse(X - empq_vec[i] > 0, 1, 0))
  cat(paste("\nEl valor de K es",toString(K), sep = " "))
  
  # find s
  fails <- sum( (pbinom(q = 0:n,size = n,prob = 1 - q_vec[i]) < alpha)) #pbinom y de cumulative dist, number of fails
  s <- n - fails
  cat(paste("\nEl valor de s es",toString(s), sep = " "))
  
  #test Hip
  test <- ifelse(K <= (n - s),'cierta','falsa')
  cat(paste("\n La prueba de hipótesis es",test, sep = " "))
}



```

#### Forma con la estadistica de orden X_{s}

```{r, 'ej5 SOrder'}
cat("Pruebas de hipótesis para Kp")
for(i in 1:3)
{
  cat(paste("\n\n Para p = ",toString(i), sep = " "))
  # find s
  fails <- sum( (pbinom(q = 0:n,size = n,prob = 1 - q_vec[i]) < alpha)) #pbinom y de cumulative dist, number of fails
  s <- n - fails
  cat(paste("\nEl valor de s es",toString(s), sep = " "))
  
  #find X(s)
  Xs <- X[s+1]  #s can start from cero
  cat(paste("\nEl valor de X(s) es",toString(Xs), sep = " "))
  cat(paste("\nEl valor de kp es",toString(empq_vec[i]), sep = " "))
  
    
  #test Hip
  test <- ifelse(Xs <= empq_vec[i],'cierta','falsa')
  cat(paste("\n La prueba de hipótesis es",test, sep = " "))
}




```

# Ejercicio 10

- 12 escenarios para contar muertos por epidemia por cada medicamento.

```{r, 'ej10 data'}
# data
medA <- c(41,8,65,28,11,15,73,54,7,50,59,24)
medB <- c(38,14,41,31,8,18,48,32,7,37,42,48)
escen <- 1:12
data <- data.frame(x = cbind(escen,medA,medB))

kable(data, col.names = c("Escenario","Meidicina A","Medicina B"))

```

## Gráfica de dispersión

```{r,'ej10 Graphdisp'}

g_ej10_points <- ggplot(data = data, mapping = aes(x = medA, y = medB)) + 
                  geom_point(col = "blue", alpha = 0.5, size = 5) + xlab("Medicina A") + ylab("Medicina B") + ggtitle("Gráfica de dispersión")
                  
g_ej10_points
```

## Correlación Spearman y de Kendall

```{r,'Ej10 Spearman y Kendall'}
rho_s <-  cor(x = data$x.medA,y = data$x.medB,method = "spearman")
tau_k <- cor(x = data$x.medA,y = data$x.medB,method = "kendall")
```

Vemos que la correlación de Spearman $\rho$, es `r rho_s`. Mientras que la correlación de Kendall $\tau$, es `r tau_k`.





